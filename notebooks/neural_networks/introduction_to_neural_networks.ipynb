{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Introduction\n",
    "\n",
    "> Heavily based on the Data Science from Scratch book by Joel Grus. 2nd edition.\n",
    "\n",
    "An _Artificial Neural Network_ (or just Neural Network) is predictive model based on the human brain dynamic, which is composed by a network of neurons. Each neuron analises the output of the previous layer and applies a function to it, activating (if the output is above a certain threshold) or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing some basic linear algebra functions\n",
    "Those functions will be used to some of the later implementations, and were showed earlier in the Joel Grus' book.\n",
    "You can check chapter 4 of the book for some explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(v: np.array, w: np.array) -> float:\n",
    "    \"\"\"Computes v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    assert len(v) == len(w), \"Vectors must be of the same length\"\n",
    "\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons\n",
    "\n",
    "The simplest neural network is the _perceptron_, which is a single neuron that takes several binary inputs and produces a single binary output. The perceptron computes a weighted sum of its inputs and \"fires\" if that weighted sum is zero or greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function(x: float) -> float:\n",
    "    return 1.0 if x >= 0 else 0.0\n",
    "\n",
    "\n",
    "def perceptron_output(weights: np.array, bias: float, x: np.array) -> float:\n",
    "    \"\"\"Returns 1 if the perceptron activates, 0 otherwise\"\"\"\n",
    "    calculation = dot(weights, x) + bias\n",
    "    return step_function(calculation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron differenciate the two halves of the space by an hyperplane of the x dots, where:\n",
    "\n",
    "```python\n",
    "dot(weights, x) + bias == 0\n",
    "```\n",
    "\n",
    "When weights are choosed correctly, the perceptrons can solve simple logic problems. For example, we can create a _AND gate_ (which returns 1 if both entries are 1, and 0 if one of the entries are 0) with the following weights and bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "and_weights = np.array([2., 2])\n",
    "and_bias = -3.0\n",
    "\n",
    "print(perceptron_output(and_weights, and_bias, [1, 1]))  # == 1\n",
    "print(perceptron_output(and_weights, and_bias, [0, 1]))  # == 0\n",
    "print(perceptron_output(and_weights, and_bias, [1, 0]))  # == 0\n",
    "print(perceptron_output(and_weights, and_bias, [0, 0]))  # == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If both entries are 1, the `calculation` would be equal to $2 + 2 - 3 = 1$ and the output would be 1. If only one of the entries is 1, the `calculation` would be equal to $2 + 0 - 3 = -1$ and the output would be 0. And if both entries are 0, the `calculation` would be equal to $-3$ and the output would be 0.\n",
    "\n",
    "With a similar logic, we can create a _OR gate_ (which returns 1 if one of the entries are 1, and 0 if both entries are 0) with the following weights and bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "or_weights = np.array([2., 2])\n",
    "or_bias = -1.0\n",
    "\n",
    "print(perceptron_output(or_weights, or_bias, [1, 1]))  # == 1\n",
    "print(perceptron_output(or_weights, or_bias, [0, 1]))  # == 1\n",
    "print(perceptron_output(or_weights, or_bias, [1, 0]))  # == 1\n",
    "print(perceptron_output(or_weights, or_bias, [0, 0]))  # == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same logic, we can create a _NOT gate_ (which returns 1 if the entry is 0, and 0 if the entry is 1) with the following weights and bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "not_weights = np.array([-2.])\n",
    "not_bias = 1.\n",
    "\n",
    "print(perceptron_output(not_weights, not_bias, [0]))  # == 1\n",
    "print(perceptron_output(not_weights, not_bias, [1]))  # == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, some problems can't be solved with only one perceptron. For example, even if you try, you wouldn't be able to use a perceptron to solve the _XOR gate_ that generates a $1$ output if one of the entries are $1$ and $0$. Here, we start to think about more complex Neural Networks.\n",
    "\n",
    "Of course, it is not necessary to use perceptrons and neurons to create a logic gate, but it is a good way to understand how they work.\n",
    "\n",
    "```python\n",
    "and_gate = min\n",
    "or_gate = max\n",
    "xor_gate = lambda x, y: 1 if x != y else 0\n",
    "```\n",
    "\n",
    "Like real neurons, the artificial ones become more interesting when they are connected in networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
